Raw Input                                | Tokens                                                       | Prediction                                                   | Issues
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Frau Dipl.-Ing. Petra Schneider          | Frau(SALUTATION), Dipl.-Ing.(TITLE), Petra(WORD), Schneider(WORD) | Sal:Frau Tit:[] Giv:Petra Fam:schneider Suf:[] Par:[]        | Missing Title: Dipl.-Ing.
Mrs. Karin de Jones                      | Mrs.(SALUTATION), Karin(WORD), de(PARTICLE), Jones(WORD)     | Sal:Mrs Tit:[] Giv:Karin Fam:jones Suf:[] Par:['de']         | 
Mr. Robert Schneider                     | Mr.(SALUTATION), Robert(WORD), Schneider(WORD)               | Sal:Mr Tit:[] Giv:Robert Fam:schneider Suf:[] Par:[]         | 
Prof. Dr. Petra Brown                    | Prof.(TITLE), Dr.(TITLE), Petra(WORD), Brown(WORD)           | Sal: Tit:[] Giv:Petra Fam:brown Suf:[] Par:[]                | 
Dr. med. Robert Brown                    | Dr.(TITLE), med.(TITLE), Robert(WORD), Brown(WORD)           | Sal: Tit:[] Giv:Robert Fam:brown Suf:[] Par:[]               | 
James Brown PhD                          | James(WORD), Brown(WORD), PhD(DEGREE)                        | Sal: Tit:[] Giv:James Fam:brown Suf:[] Par:[]                | Missing PhD

Champion Tree: make_name_obj(if_bool_string(FALSE, EMPTY_STR, raw_input), trim(extract_salutation_str(get_tokens_before_comma(tokenize(raw_input)))), extract_suffix_list(get_remainder_tokens(tokenize(get_first_string(extract_suffix_list(get_remainder_tokens(drop_first(EMPTY_TOK_LIST), tokenize(if_bool_string(TRUE, raw_input, EMPTY_STR)))))), tokenize(if_bool_string(TRUE, raw_input, EMPTY_STR)))), trim(extract_given_str(tokenize(trim(raw_input)))), trim(to_lower(extract_family_str(tokenize(raw_input)))), extract_middle_str(tokenize(raw_input)), FEMALE, extract_suffix_list(get_remainder_tokens(remove_type(EMPTY_TOK_LIST, WORD), remove_type(slice_tokens(remove_type(tokenize(if_bool_string(TRUE, raw_input, to_lower(if_bool_string(FALSE, raw_input, EMPTY_STR)))), identity_token_type(DEGREE)), TRUE, is_suffix(EMPTY_TOKEN)), identity_token_type(PARTICLE)))), extract_particles_list(tokenize(if_bool_string(FALSE, get_first_string(extract_suffix_list(EMPTY_TOK_LIST)), if_bool_string(is_particle(get_first_token(remove_type(EMPTY_TOK_LIST, identity_token_type(DEGREE)))), extract_salutation_str(slice_tokens(remove_type(EMPTY_TOK_LIST, WORD), count_type(tokenize(to_lower(to_lower(EMPTY_STR))), identity_token_type(TITLE)), index_of_type(remove_type(EMPTY_TOK_LIST, identity_token_type(DEGREE)), identity_token_type(PARTICLE)))), to_lower(raw_input))))))
